---
title: "init"
author: "Nate Thomas"
date: "1/17/2022"
output:
  word_document: default
  html_document: default
---

```{r}
library(tidyverse)
library(skedastic)
library(lubridate)
library(rvest)
library(readxl)
library(moments)
library(car)
library(ggplot2)
library(TSA)
library(stringr)
library(ggplot2)
library(reshape2)
```

# Initalialization 

Source:
https://www.kaggle.com/vagifa/usa-commodity-prices?select=commodity-prices-2016.csv

```{r}
commodity2016 <- read_csv('../DataSet/commodity prices/commodity-prices-2016.csv') %>% as_tibble()

df <- commodity2016 %>% select(Date,`Industrial Inputs Price Index`) %>% 
  mutate(Date_form = as.Date(Date, format = "%m/%d/%Y"),
         Year = year(Date_form),
         Month = month(Date_form, abbr = FALSE),
         IIPI = `Industrial Inputs Price Index`) %>%
  select(Date_form,Year,Month,IIPI)

plot(df$Date_form,df$IIPI)
```

```{r}
p1 <- df %>% 
  ggplot(aes(x = Date_form, y = IIPI)) +
  geom_point() +
  labs(title = 'IIPI from 1980 to 2016',
        x = 'Year of observation',
        y = 'IIPI')
```

# Data Set review and assessment

## Time Series decomposition

```{r}
df.ts <- ts(df$IIPI, start=c(1980,1), frequency = 12)

plot(aggregate(df.ts))
plot(decompose(df.ts))
```

## White Noise Process Evaluation

The Ljung-Box Q-statistic Test is used to confirm existence of autocorrelation within the commodity index.

```{r}
Box.test(df$IIPI,lag=36)
```

H0: All autocorrelctions are zero (0)

Ha: at least one (1) autocorrelation is not zero (0)

The test indicates one can safely reject the null hypothesis (H0) - such that at least one (1) autocorrleation is not zero.

```{r}
acf(df$IIPI, lag.max=36)
```

Based on the autocorrelation chart displayed one can be confident that there exists autocorrelation to a great degree, across the three years of lag values shown.

Therefore one can safely conclude that this is not a white noise process.

In reviewing the possibility of constant mean, to conclude that the time series data is a white noise process one can create a linear model with respect to time and assess the the t-test of the slope coefficient. If this is a non-zero value, no further action is required, as this definitionally determines that this is not a constant mean process.  However, one must assume that the residuals are t-distributed for this to hold for simple linear regression.

```{r}
slm <- lm(IIPI~Date_form, data = df)
summary(slm)
```

To confirm the residual normality assumption, the Shapiro-Wilks test is performed:

```{r}
shapiro.test(rstandard(slm))
hist(rstandard(slm),breaks=20, col="steelblue")
```

H0: The residuals are normally distributed.
Ha: The residuals are not normally distributed.

The residuals are not normally distributed, as seen in the Shapiro-Wilk test and associated histogram, above for the simple linear regression with respect to time.

Ljung-Box Q-statistic Test is used to confirm existence of autocorrelation within the residuals of commodity index function with respect to time. 

```{r}
Box.test(rstandard(slm), lag=36)
```
H0: All autocorrelctions are zero (0)
Ha: at least one (1) autocorrelation is not zero (0)

The test indicates one can safely reject the null hypothesis (H0) - such that at least one (1) autocorrleation is not zero.

```{r}
acf(rstandard(slm))
```

The autocorrolation function chart shown above indicates that the residuals of the commodity index model with respect to time are strongly autocorrelated to one another. 

Finally, White's Test for heteroscedasticity is performed on the model residuals to test for constant variance:

```{r}
white_lm(slm, interactions = TRUE)
```

H0: There is no heteroscedasticity.
Ha: There is heteroscedasticity.

Based on the p-value above, the residuals of the model with respect to time have non-constant variance.

# First Difference White Noise Process Evaluation

```{r}
df <- df %>% 
  mutate(IIPI_dif = IIPI - lag(IIPI)) %>%
  drop_na()
```

## Time Series decomposition

```{r}
df_dif.ts <- ts(df$IIPI_dif, start=c(1980,1), frequency = 12)

plot(aggregate(df_dif.ts))
plot(decompose(df_dif.ts))
```

The Ljung-Box Q-statistic Test is used to confirm existence of autocorrelation within the commodity index first difference.

```{r}
Box.test(df$IIPI_dif,lag=36)
```

H0: All autocorrelctions are zero (0)

Ha: at least one (1) autocorrelation is not zero (0)

The test indicates one can safely reject the null hypothesis (H0) - such that at least one (1) autocorrleation is not zero.

```{r}
acf(df$IIPI_dif, lag.max=36)
```

Based on the autocorrelation chart displayed one can be confident that there exists much reduced autocorrelation compared to the original dataset.  This however, is not a randomm walk process, as there are autocorrelations at lag values equal to 1 and 2.

Therefore one is able to conclude that this is not a white noise process, though the evidence.  

Again, a simple linear regression model with respect to time is created to test for contstant mean.  This, again, is preconditioned on the assumption that the residuals are normal.

```{r}
slm_dif <- lm(IIPI_dif~Date_form, data = df)
summary(slm_dif)
```

The Shapiro-Wilks test is performed to confirm if the residuals are normally distributed:

```{r}
shapiro.test(rstandard(slm_dif))
hist(rstandard(slm_dif),breaks=20, col="steelblue")
```

H0: The residuals are normally distributed.
Ha: The residuals are not normally distributed.

The residuals are not normally distributed, as seen in the Shapiro-Wilk test and associated histogram, above.

Ljung-Box Q-statistic Test is used to confirm existence of autocorrelation within the residuals of commodity index function with respect to time. 

```{r}
Box.test(rstandard(slm_dif), lag=36)
```
H0: All autocorrelctions are zero (0)
Ha: At least one (1) autocorrelation is not zero (0)

The test indicates one can safely reject the null hypothesis (H0) - such that at least one (1) autocorrleation is not zero.

```{r}
acf(rstandard(slm_dif))
```

The autocorrolation function chart shown above indicates that the residuals of the commodity index model with respect to time are  autocorrelated at lag 1 and 2. 

Finally, White's Test for heteroscedasticity is performed on the model residuals to test for constant variance:

```{r}
white_lm(slm_dif, interactions = TRUE)
```

H0: There is no heteroscedasticity.
Ha: There is heteroscedasticity.

Based on the p-value above, the residuals of the model with respect to time have non-constant variance.

# Predictors

## T-bill rate 

Source:
https://finance.yahoo.com/quote/%5EIRX/history?period1=317088000&period2=1453161600&interval=1d&filter=history&frequency=1d&includeAdjustedClose=true

```{r}
tbill <- read_csv('../DataSet/commodity prices/1-tbill13week.csv') %>% as_tibble() %>%
  mutate(Date_form = as.Date(Date, format = "%m/%d/%Y"),
         Open = as.double(Open),
         High = as.double(High),
         Low = as.double(Low),
         Close = as.double(Close),
         AdjClose = as.double(`Adj Close`),
         Volume = as.double(Volume),
         Month = month(Date_form),
         Year = year(Date_form)) %>% 
  drop_na() %>%
  group_by(Year,Month) %>%
  summarise(TBillClose = mean(Close)) %>%
  mutate(Date_form = as.Date(paste(Year,Month,"01",sep="-"))) %>%
  select(Date_form,Year,Month,TBillClose)
  
plot(tbill$TBillClose)
```

## GDP

https://fred.stlouisfed.org/series/BBKMGDP

```{r}
gdp <- read_csv('../DataSet/commodity prices/2-GDPC1.csv') %>% as_tibble() %>%
  mutate(Date_form = as.Date(DATE, format = "%m/%d/%Y"),
         Month = month(Date_form),
         Year = year(Date_form),
         GDP = GDPC1) %>%
  select(Date_form,Year, Month, GDP)

gdp$Date_form[1]
gdp$Date_form[length(gdp$Date_form)]
seq.Date(gdp$Date_form[1], length.out = length(gdp$Date_form)*3-2, by = "month")

gdp <- left_join(data_frame(Date_form=seq.Date(gdp$Date_form[1], length.out = length(gdp$Date_form)*3-2, by = "month")), gdp, by = 'Date_form') %>% 
  fill(everything(), .direction = "down") %>%
  mutate(Month = month(Date_form))

plot(gdp$GDP)
```

## Inflation Rate, yearly

https://www.thebalance.com/u-s-inflation-rate-history-by-year-and-forecast-3306093#:~:text=U.S.%20Inflation%20Rate%20History%20and%20Forecast%20%20,FFR%20midpoint%20projection%20%2037%20more%20rows%20

```{r}
inflation_yearly <- read_xlsx('../DataSet/commodity prices/3-annual-inflation-rate.xlsx', sheet = 'Sheet1') %>%
  as_tibble() %>%
  mutate(Year = as.double(Year),
         Inf_Rate = as.double(`Inflation Rate YOY4`)) %>%
  select(Year, Inf_Rate) %>%
  drop_na()
inflation_yearly
```

## Inflation Rate, Annualized Monthly value

https://www.multpl.com/inflation/table/by-month

```{r}
inflation_monthy <- read_xlsx('../DataSet/commodity prices/4-monthly-inflation.xlsx', sheet = 'Sheet1') %>%
  as_tibble() %>%
  mutate(Date_form = as.Date(Date),
         Year = year(Date_form),
         Month = month(Date_form),
         InfRate = as.double(Value)*100) %>%
  select(Date_form, Month, Year, InfRate) %>%
  drop_na()
inflation_monthy

plot(inflation_monthy$InfRate)
```

## Industrial Production

```{r}
indpro_monthy <- read_csv('../DataSet/commodity prices/5-INDPRO.csv') %>%
  as_tibble() %>%
  mutate(Date_form = as.Date(DATE, format = '%Y-%m-%d'),
         Year = year(Date_form),
         Month = month(Date_form),
         IndPro = INDPRO) %>%
  select(Date_form, Month, Year, IndPro) %>%
  drop_na()
indpro_monthy

plot(indpro_monthy$IndPro)
```

```{r}
moneysupply <- read_csv('../DataSet/commodity prices/6-money-supply.csv') %>%
  as_tibble() %>%
  mutate(Date_form = as.Date(paste(`Time Period`,"-01", sep =""), format = '%Y-%m-%d'),
         Year = year(Date_form),
         Month = month(Date_form),
         M2 = M2_N.M) %>%
  select(Date_form, Month, Year, M2) %>%
  drop_na()
moneysupply

plot(moneysupply$M2)
```

```{r}
unemployment <- read_csv('../DataSet/commodity prices/7-unemployment.csv') %>%
  as_tibble() %>%
  mutate(Date_form = as.Date(Date, format = '%d-%B-%y'),
         Year = year(Date_form),
         Month = month(Date_form),
         UnempRate = Rate*100) %>%
  select(Date_form, Month, Year, UnempRate) %>%
  drop_na()
unemployment

plot(unemployment$UnempRate)
```

```{r}
recession <- read_csv('../DataSet/commodity prices/8-USREC.csv') %>%
  as_tibble() %>%
  mutate(Date_form = as.Date(DATE),
         Year = year(Date_form),
         Month = month(Date_form),
         Recession = USREC) %>%
  select(Date_form, Month, Year, Recession) %>%
  drop_na()
recession

plot(recession$Recession)
```

Combine all the proposed predictor datasets.

```{r}
df <- left_join(df, tbill, by = c('Date_form','Year','Month'))
df <- left_join(df, gdp, by = c('Date_form','Year','Month'))
df <- left_join(df, inflation_monthy, by = c('Date_form','Year','Month'))
df <- left_join(df, indpro_monthy, by = c('Date_form','Year','Month'))
df <- left_join(df, moneysupply, by = c('Date_form','Year','Month'))
df <- left_join(df, unemployment, by = c('Date_form','Year','Month'))
df <- left_join(df, recession, by = c('Date_form','Year','Month'))

df.ts.modelset <- df %>% select(-c(Year,Month,IIPI_dif)) %>% drop_na()
df.ts.modelset

df.ts.modelset.test <- df.ts.modelset[424:433,]
df.ts.modelset.train <- df.ts.modelset[1:423,]
```

```{r}
mlm.ts <- lm(IIPI~., data = df.ts.modelset.train %>% select(-Date_form))
summary(mlm.ts)

round(mlm.ts$coefficients,3)

names(mlm.ts$coefficients)[2:length(names(mlm.ts$coefficients))] %>% paste(sep = " ")
```

```{r}
shapiro.test(rstandard(mlm.ts))
hist(rstandard(mlm.ts),breaks=20, col="steelblue")
```

```{r}
vif(mlm.ts)
```

```{r}
mlm.ts1 <- lm(IIPI~., data = df.ts.modelset.train %>% select(-c(Date_form,GDP)))
summary(mlm.ts1)
```

```{r}
shapiro.test(rstandard(mlm.ts1))
hist(rstandard(mlm.ts1),breaks=20, col="steelblue")
```

```{r}
vif(mlm.ts1)
```

```{r}
mlm.ts2 <- lm(IIPI~., data = df.ts.modelset.train %>% select(-c(Date_form,GDP,IndPro)))
summary(mlm.ts2)
```

```{r}
shapiro.test(rstandard(mlm.ts2))
hist(rstandard(mlm.ts2),breaks=20, col="steelblue")
```

```{r}
vif(mlm.ts2)
```
```{r}
predict(mlm.ts2, df.ts.modelset.test %>% select(-c(IIPI,Date_form,GDP,IndPro)), interval="prediction")
```
```{r}
mlm.ts3 <- lm(log(IIPI)~., data = df.ts.modelset.train %>% select(-c(Date_form,GDP,IndPro,TBillClose)))
```

```{r}
shapiro.test(rstandard(mlm.ts3))
hist(rstandard(mlm.ts3),breaks=20, col="steelblue")
```

```{r}
vif(mlm.ts3)
```

```{r}
predict(mlm.ts3, df.ts.modelset.test %>% select(-c(IIPI,Date_form,GDP,IndPro,TBillClose)), interval="prediction")
```

```{r}
white_lm(mlm.ts3)
```

```{r}
mlm.ts4 <- lm(sqrt(IIPI)~., data = df.ts.modelset.train %>% select(-c(Date_form,GDP,IndPro,TBillClose)))
summary(mlm.ts4)
```

```{r}
shapiro.test(rstandard(mlm.ts4))
hist(rstandard(mlm.ts4),breaks=20, col="steelblue")
```

```{r}
vif(mlm.ts4)
```
```{r}
predict(mlm.ts4, df.ts.modelset.test %>% select(-c(IIPI,Date_form,GDP,IndPro,TBillClose)), interval="prediction")
```

```{r}
white_lm(mlm.ts4)
```


```{r}
summary(mlm.ts2)$adj.r.squared
summary(mlm.ts3)$adj.r.squared
summary(mlm.ts4)$adj.r.squared
```


## Deterministic Model

```{r}
df.ts.modelset.deterministic <- df %>% select(-c(Year,Date_form,IIPI_dif,TBillClose,GDP,InfRate,IndPro,M2,UnempRate,Recession)) %>% drop_na()

df.ts.modelset.deterministic$Month

df.ts.modelset.deterministic <- cbind(df.ts.modelset.deterministic,1:length(df.ts.modelset.deterministic$IIPI)) %>% 
  mutate(index = `1:length(df.ts.modelset.deterministic$IIPI)`,
         Month = as.factor(Month)) %>%
  select(index, Month, IIPI)


df.ts.modelset.deterministic.test <- df.ts.modelset.deterministic[424:433,]
df.ts.modelset.deterministic.train <- df.ts.modelset.deterministic[1:423,]
```


## Indicator Variable Model Seasonal Model with Trend

```{r}
dlm.ts1 <- lm(IIPI~index+Month, data = df.ts.modelset.deterministic.train)
summary(dlm.ts1)
```

```{r}
Box.test(rstandard(dlm.ts1))
acf(rstandard(dlm.ts1))
```

```{r}
kfind <- function(d) {
  r2adjust <- 0
  for (k in 1:30){
    lm_summary_temp <- lm(IIPI~poly(index,k),data = d) %>% summary()
    print(k)
    print(lm_summary_temp$adj.r.squared)
    if (lm_summary_temp$adj.r.squared>r2adjust){
      k_opt <- k
    }
    if(lm_summary_temp$adj.r.squared<=r2adjust){
      break
    }
    r2adjust<-lm_summary_temp$adj.r.squared
  }
  return(k_opt)
}

k <- kfind(df.ts.modelset.deterministic.train)

dlm.ts2 <- lm(IIPI~poly(index,k), data = df.ts.modelset.deterministic.train)
summary(dlm.ts2)
```

```{r}
df.ts.modelset.harmonic <- df.ts.modelset.deterministic %>% select(-Month)

detrend<-lm(IIPI~index, data=df.ts.modelset.deterministic.train)
periodogram(detrend$residuals)

harmonics <- order(periodogram(detrend$residuals)$spec, decreasing = TRUE)[1:100]
```


```{r}
listgen <- function(t,j,h,s){
  sin_df <- tibble(rep(NA,length(t)))
  cos_df <- tibble(rep(NA,length(t)))
  for (i in 1:j){
    sinx = sin(2*pi*t*h[i]/length(s))
    cosx = cos(2*pi*t*h[i]/length(s))
    sin_df <- cbind(sin_df,sinx)
    cos_df <- cbind(cos_df,cosx)
  }
  colnames(sin_df) = c('temp',paste('sin',h,sep=""))
  colnames(cos_df) = c('temp',paste('cos',h,sep=""))
  sin_df <- sin_df %>% select(-temp)
  cos_df <- cos_df %>% select(-temp)
  df <- cbind(sin_df,cos_df)
  return(df)
}

trigf <- listgen(df.ts.modelset.harmonic$index,length(harmonics),harmonics,df.ts.modelset.harmonic$IIPI)

df.ts.modelset.harmonic <- df.ts.modelset.harmonic %>% cbind(trigf)

df.ts.modelset.harmonic.test <- df.ts.modelset.harmonic[424:433,]
df.ts.modelset.harmonic.train <- df.ts.modelset.harmonic[1:423,]
```

```{r}
dlm.ts3<- lm(IIPI~., data = df.ts.modelset.harmonic.train)
dlm.ts3.summary <-  summary(dlm.ts3)
which(dlm.ts3.summary$coefficients[,'Pr(>|t|)']>0.05) %>% names()
```

```{r}
termsforassessment <- which(dlm.ts3.summary$coefficients[,'Pr(>|t|)']>0.05) %>% names() %>% tibble()
sins <- termsforassessment %>% filter(str_detect(.,'sin'))
coss <- termsforassessment %>% filter(str_detect(.,'cos'))

remove <- intersect(sins$`.` %>% str_extract(.,"(\\d+)"), coss$`.` %>% str_extract(.,"(\\d+)"))

termsforassessment <- termsforassessment$`.`
termsforremoval1 <- termsforassessment[termsforassessment %in% paste('sin',remove ,sep='')]
termsforremoval2 <-termsforassessment[termsforassessment %in% paste('cos',remove ,sep='')]
termsforremoval <- cbind(termsforremoval1,termsforremoval2) %>% c()
termsforremoval
```

```{r}
dlm.ts4<- lm(IIPI~., data = df.ts.modelset.harmonic.train %>% select(-all_of(termsforremoval)))
dlm.ts4.summary <-  summary(dlm.ts4)
dlm.ts4.summary

length(df.ts.modelset.harmonic.train) - length(df.ts.modelset.harmonic.train %>% select(-all_of(termsforremoval)) %>% names())
```

However, this clearly overfits the data.

So as alterative the model is incrementaly increased in terms, until the Adjusted R squared does not increase. 

```{r}
harmiclmgen <- function(d,harmonics){
  t <- d$index
  j <- length(harmonics)
  h = harmonics
  r2adj <- list()
  bic <- list()
  aic <- list()
  for (ix in 1:j) {
    sin_df <- tibble(rep(NA,length(t)))
    cos_df <- tibble(rep(NA,length(t)))
      for (i in 1:ix){
        sinx = sin(2*pi*t*h[i]/length(t))
        cosx = cos(2*pi*t*h[i]/length(t))
        sin_df <- cbind(sin_df,sinx)
        cos_df <- cbind(cos_df,cosx)
      }
    colnames(sin_df) = c('temp',paste('sin',h[1:ix],sep=""))
    colnames(cos_df) = c('temp',paste('cos',h[1:ix],sep=""))
    sin_df <- sin_df %>% select(-temp)
    cos_df <- cos_df %>% select(-temp)
    df <- d %>% cbind(cos_df) %>% cbind(sin_df)  
    df.train <-  df[1:423,]
    lms <- lm(IIPI~., data = df.train)
    lms_sum <- summary(lms)
    r2adj[ix] <- lms_sum$adj.r.squared
    bic[ix] <- BIC(lms)
    aic[ix] <- AIC(lms)
  }
  return(list(numh = 1:ix,r2adj = r2adj,bic = bic, aic = aic))
}

dlm.ts5 <- harmiclmgen(df.ts.modelset.deterministic %>% select(-Month),harmonics)

dlm.ts.r2tlb <- tibble(numh = dlm.ts5$numh %>% unlist(), 
r2adj = dlm.ts5$r2adj %>% unlist(), bic = dlm.ts5$bic %>% unlist(), aic = dlm.ts5$aic %>% unlist())
dlm.ts.r2tlb
```

```{r}
dlm.ts.r2tlb %>% mutate(lead = lead(r2adj)<r2adj) %>% filter(lead)
```
However, the adjusted R-squared does not decrease until using 85 harmonics.

Therefore, instead the visual elbow method is used as alternative.

```{r}
plot(dlm.ts.r2tlb$r2adj)
plot(dlm.ts.r2tlb$bic)
plot(dlm.ts.r2tlb$aic)
```

Taking the number of harmonics before the reduced rate of increase in adjusted R-squared to be 15.

```{r}
trigf1 <- listgen(df.ts.modelset.harmonic$index,15,harmonics[1:15],df.ts.modelset.harmonic$IIPI)

df.ts.modelset.harmonic1 <- df.ts.modelset.deterministic %>% select(-Month) %>% cbind(trigf1)

df.ts.modelset.harmonic.test1 <- df.ts.modelset.harmonic1[424:433,]
df.ts.modelset.harmonic.train1 <- df.ts.modelset.harmonic1[1:423,]

dlm.ts6<- lm(IIPI~., data = df.ts.modelset.harmonic.train1 )
dlm.ts6.summary <-  summary(dlm.ts6)
which(dlm.ts6.summary$coefficients[,'Pr(>|t|)']>0.05) %>% names()
```

```{r}
trigf2 <- listgen(df.ts.modelset.harmonic$index,65,harmonics[1:65],df.ts.modelset.harmonic$IIPI)

df.ts.modelset.harmonic2 <- df.ts.modelset.deterministic %>% select(-Month) %>% cbind(trigf2)

df.ts.modelset.harmonic.test2 <- df.ts.modelset.harmonic2[424:433,]
df.ts.modelset.harmonic.train2 <- df.ts.modelset.harmonic2[1:423,]

dlm.ts7<- lm(IIPI~., data = df.ts.modelset.harmonic.train2 )
dlm.ts7.summary <-  summary(dlm.ts7)
which(dlm.ts7.summary$coefficients[,'Pr(>|t|)']>0.05) %>% names()
```

```{r}
df.ts.modelset
df.ts.modelset.test 
df.ts.modelset.train 
```

```{r}
acf(df.ts.modelset$IIPI)
```

Non-statoinary...

```{r}
acf(diff(df.ts.modelset$IIPI))
```

Stationary but with periodic decay

```{r}
pacf(diff(df.ts.modelset$IIPI))
```

Also shows periodic decay.

```{r}
arima_aic_find <- function(){
  p_index <- list()
  q_index <- list()
  arima_aic <- list()
  for (p in 0:10){
    for (q in 0:10){
      if(p == 0){
        p_index <- p_index %>% append(p)
        q_index <- q_index %>% append(q)
        arima_aic <- arima_aic %>% append(arima(df.ts.modelset.train$IIPI, order = c(p,1,q))$aic)
      }
      if (q == 0){
        p_index <- p_index %>% append(p)
        q_index <- q_index %>% append(q)
        arima_aic <- arima_aic %>% append(arima(df.ts.modelset.train$IIPI, order = c(p,1,q))$aic)
      }
      if ((p+q) <= 4){
        p_index <- p_index %>% append(p)
        q_index <- q_index %>% append(q)
        arima_aic <- arima_aic %>% append(arima(df.ts.modelset.train$IIPI, order = c(p,1,q))$aic)        
      }
    }
  }
  return(tibble(p_index,q_index,arima_aic))
}

arima_table <- arima_aic_find() %>% unnest() %>% unique()
arima_table
```

```{r}
ggplot(arima_table, aes(x = p_index, y = q_index, fill = arima_aic)) + 
  geom_tile(color = "black") + 
  scale_fill_gradientn(colors = hcl.colors(20,"RdYlGn")) + 
  coord_fixed()
```

```{r}
arima_table %>% arrange(arima_aic) %>% head(3)
```

```{r}
arima210 <- arima(df.ts.modelset.train$IIPI, order = c(2,1,0))
arima111 <- arima(df.ts.modelset.train$IIPI, order = c(1,1,1))
arima015 <- arima(df.ts.modelset.train$IIPI, order = c(0,1,5))
```

```{r}
df.ts.modelset.test
```

```{r}
predictions_armatemp <- list()

y = df.ts.modelset.train$IIPI

for (i in 1:(dim(df.ts.modelset.test)[1])){
  armatemp <- arima(y, order = c(2, 1, 0))
  predictions_armatemp[[i]] <- predict(armatemp, n.ahead = 1)$pred
  y <- y %>% append(df.ts.modelset.test[i,'IIPI']) %>% unlist()
}

pred.arima2101step <- predictions_armatemp %>% unlist()
```

```{r}
predictions_armatemp <- list()

y = df.ts.modelset.train$IIPI

for (i in 1:(dim(df.ts.modelset.test)[1])){
  armatemp <- arima(y, order = c(1, 1, 1))
  predictions_armatemp[[i]] <- predict(armatemp, n.ahead = 1)$pred
  y <- y %>% append(df.ts.modelset.test[i,'IIPI']) %>% unlist()
}

pred.arima1111step <- predictions_armatemp %>% unlist()
```

```{r}
arima_aic_find_param <- function(d,diff){
  p_index <- list()
  q_index <- list()
  arima_aic <- list()
  for (p in 0:10){
    for (q in 0:10){
      if(p == 0){
        p_index <- p_index %>% append(p)
        q_index <- q_index %>% append(q)
        arima_aic <- arima_aic %>% append(arima(d, order = c(p,diff,q))$aic)
      }
      if (q == 0){
        p_index <- p_index %>% append(p)
        q_index <- q_index %>% append(q)
        arima_aic <- arima_aic %>% append(arima(d, order = c(p,diff,q))$aic)
      }
      if ((p+q) <= 4){
        p_index <- p_index %>% append(p)
        q_index <- q_index %>% append(q)
        arima_aic <- arima_aic %>% append(arima(d, order = c(p,diff,q))$aic)        
      }
    }
  }
  return(tibble(p_index,q_index,arima_aic))
}

arima_table <- arima_aic_find_param(rstandard(dlm.ts6),0) %>% unnest() %>% unique()
arima_table
```

```{r}
dlm.ts6.arima211 <- arima(coh94_tranformed, order =c(2,1,1), xreg = data1 %>% select(-coh94))
arima211reg
```


```{r}
save.image()
```













