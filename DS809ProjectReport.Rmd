---
title: "DS809 - Industrial Inputs Price Index"
author: "Nate Thomas"
date: "`r Sys.Date()`"
output: word_document
---

```{r echo = FALSE, message=FALSE, results='hide'}
load('.RData')
library(dplyr)
library(car)
library(skedastic)
```

# Introduction and Overview

This project endeavors to provide example implementation of the various methods outlined in DS809 Time Series to model the commodity Industrial Inputs Price Index from 1980 through 2016. The Industrial Input Price Index, hereafter IIPI, is provided by the IMF in the IMF Primary Commodity Prices Report (*IMF Primary Commodity Prices*, 2021). As a break-out index it does not include energy commodities (Coal, Natural Gas, Spot Crude, Propane) but does include Agricultural raw materials (Cotton, Hides, Rubber, Timber, Wool), metals (Aluminum, Cobalt, Copper, Iron Ore, Lead, Molybdenum, Nickel, Tin, Uranium, and Zinc), and precious metals (Gold, Palladium, Platinum, Silver). The commodity prices used are weighted averages representative of the global market, corrected for volume, as determined by the largest import markets for the commodity constituents. The purpose of the index is to provide a relative indicator (here indexed to 2005 = 100) for assessment of the commodities in question.

The first task performed for this project was to create the time series dataset using *Predictive Dynamics in Commodity Prices* (Gargano & Timmerman, 2012) as a loose framework with select variables therein. The following data were collected and organized for subsequent analysis.

A. IIPI (Aliyev, 2020), Dependent Variable and Date index. tags: **IIPI, Date_form**. This dataset defined the time frame of interest (1980-02-01 to 2016-02-01). All other datasets were selected contingent upon their inclusion of this timeframe.

```{r echo = FALSE}
p1
```

B. 13 Week Treasury Bill (*US Trade - Statistics & Facts*, 2021), Independent Variable. tag: **TBillClose**.

C. US Real GDP (*Real Gross Domestic Product (GDPC1)* \| *FRED* \| *St. Louis Fed*, n.d.). tag: **GDP**

D. US Inflation (*US Inflation Rate by Month*, n.d.). tag: **InfRate**

E. Industrial Production ((*Industrial Production: Total Index (INDPRO)*\| *FRED* \| *St. Louis Fed*, n.d.). tag: **IndPro**

F. Money Supply M2, (*BOARD OF GOVERNORS of the FEDERAL RESERVE SYSTEM*, 2021). tag: **M2**

G. US Unemployment, (*Employment and Unemployment*). tag: **UnempRate**

The index is indicative of global market but this project uses United States specific independent variable values as analog facsimiles for global variables when necessary. This is a recognized short-hand performed here to allow for timely and comprehensive analysis, in the absence of the global datasets for use. The United States' trade accounts for the largest percentage (13.5%) of total import trade worldwide (*US Trade - Statistics & Facts*, 2021), and therefore while this is not perfect they is used for the purposes defined here.

The first rows of the dataset are displayed after collection, cleaning, being joined according to date:

```{r echo = FALSE}
head(df.ts.modelset)
```

## Excluding White Noise Criteria

The first task when considering a dataset for time series analysis is to confirm that the variable of interest and its first difference are not "white noise processes" (WNP).  A WNP is defined by three (3) criteria, all of which must be met to conclude the data is WNP.

1) Constant Mean: $E(IIPI_t) = \mu$ for all $t$

2) Constant Variance: $Var(Y_t) = \sigma^2$ for all $t$

3) Autocorrelation is not found at all lags: $\rho_k = 0$ for all $k\geq1$

To show then that a series is not a WNP one must simply prove at least one of these constraints to be false.  

### IIPI White Noise Rejection

The Box-Pierce Test is used to confirm the existance of autocorrelation up to a defined maximum lag value (here 36 months):

Hypothesis: 

H0: All autocorrelctions are zero (0) 

Ha: At least one (1) autocorrelation is not zero (0) 

```{r echo = FALSE}
Box.test(df$IIPI,lag=36)
```

The test indicates one can safely reject the null hypothesis (H0) - such that at least one (1) autocorrleation is not zero.

This is also seen through visual inspection of the ACF chart:

```{r echo = FALSE}
acf(df$IIPI, lag.max=36)
```

Based on the autocorrelation chart displayed one can be confident that there exists autocorrelation to a great degree, across the three years of lag values shown.

### IIPI First Difference White Noise Process Rejection

Again, the Box-Pierce Q-statistic Test is used to confirm the existance of autocorrelation up to a defined maximum lag value (here 36 months):

Hypothesis: 

H0: All autocorrelctions are zero (0) 

Ha: At least one (1) autocorrelation is not zero (0) 

```{r echo = FALSE}
Box.test(df$IIPI_dif,lag=36)
```

The test indicates one can safely reject the null hypothesis (H0) - such that at least one (1) autocorrleation is not zero in the first difference series.

This is also seen through visual inspection of the ACF chart:

```{r echo = FALSE}
acf(df$IIPI_dif, lag.max=36)
```

## Visual Inspection of the Data

The data was decomposed using native R *stats* package and to visually assess the potential time series affects of IIPI.

```{r echo = FALSE}
plot(decompose(df.ts))
```

# Regression Model

## Initial Regression, with all variables

A multiple linear regression is estimated:

$$IIPI(`r names(mlm.ts$coefficients)[2:length(names(mlm.ts$coefficients))] %>% paste(sep = " ")`) = \beta_0 + \beta_1 TBillCLose + \beta_2 GDP  + \beta_3 InfRate + \beta_4 IndPro + \beta_5 M2 + \beta_6 UnempRate + \beta_7 Recession + \epsilon_t$$

, which results in the following estimated $\beta$ values:

```{r echo = FALSE}
mlm.ts$coefficients
```

The summary and analysis of these coefficients is not performed here, due to failure of all residual assumptions, as follows.

### Residual Assumptions

Before proceeding with model interpretation the regression residual assumptions must be verified:

1. $E(\epsilon_t|X_{1t},...,X_{kt}) = 0$ (zero mean assumption)

2. $Var(\epsilon_t|X_{1t},...,X_{kt}) = Var(\epsilon_t) = \sigma^2$ for all $t$ (constant variance assumption)

3. $(\epsilon_t|X_{1t},...,X_{kt}) ~N(0,\sigma^2)$ for all $t$ (normality assumption)

4. $Cov((\epsilon_t,\epsilon_h|X_{1t},...,X_{kt}) = 0$ for $t \neq h$ (error terms are not autocorrelated along the time dimension)

#### Residual Normality

The Shapiro-Wilk Test is performed to verify residual normality:

```{r}
shapiro.test(rstandard(mlm.ts))
```

$H_0$: Series are normally distributed. vs. $H_a$: Series are not normally distributed

The resulting p-value is less than 0.05, therefore $H_0$ is rejected, and one must conclude that the series are not normally distributed.

#### Residual Autocorrelation

The Box-Pierce test is performed to identify if the residuals are autocorrelated: 

```{r}
Box.test(rstandard(mlm.ts), lag=36)
```

$H_0$: $\rho_1=\rho_2=\rho_k=0$ (all autocorrelations are zero). vs. $H_a$: at least one $\rho_k \neq 0$ (at least one autocorrealtion is not zero)

The resulting p-value is less than 0.05, therefore $H_0$ is rejected, and one must conclude that at least one lag value returns a statistically significant autocorrelation.

#### Constant Variance

White's test for Heteroscedasticity is performed to confirm constant variance:

```{r}
white_lm(mlm.ts, interactions = TRUE)
```

$H_0$: There is no Heteroscedasticity (constant variance) vs. $H_a$: There is Heteroscedasticity (no constant variance)

The resulting p-value is less than 0.05, therefore $H_0$ is rejected, and one must conclude that there exists non-constant variance within the series.

### Initial Regression, ResidualSummary

All the residual assumptions failed for this initial regression.  Therefore, assessment of the coefficients is not performed here.  Subsequent methods and analysis is required to remediate the complexities presented by this dataset.

In conjunction with resolving the residual assumptions, the variance inflation factors are computed to identify any multi-collinearities.  

```{r echo = FALSE}
vif(mlm.ts)
```

Ten (10) is the typically accepted subjective value at which a variance inflation factor is considered high.  GDP, IndPro and M2 all exceed this limit.

A new linear model is therefore estimated without GDP, which has the highest VIF.

## Regression without GDP

The following multiple linear regression model is estimated:

$$IIPI(`r names(mlm.ts1$coefficients)[2:length(names(mlm.ts1$coefficients))] %>% paste(sep = " ")`) = \beta_0 + \beta_1 TBillCLose + \beta_3 InfRate + \beta_4 IndPro + \beta_5 M2 + \beta_6 UnempRate + \beta_7 Recession + \epsilon_t$$

, which results in the following estimated $\beta$ values:

```{r echo = FALSE}
mlm.ts1$coefficients
```

Again, summary and analysis of these coefficients is not performed here due to failure of all residual assumptions, as follows.

#### Residual Normality

The Shapiro-Wilk Test is performed to verify residual normality:

```{r}
shapiro.test(rstandard(mlm.ts1))
```

$H_0$: Series are normally distributed. vs. $H_a$: Series are not normally distributed

The resulting p-value is less than 0.05, therefore $H_0$ is rejected, and one must conclude that the series are not normally distributed.

#### Residual Autocorrelation

The Box-Pierce test is performed to identify if the residuals are autocorrelated: 

```{r}
Box.test(rstandard(mlm.ts1), lag=36)
```

$H_0$: $\rho_1=\rho_2=\rho_k=0$ (all autocorrelations are zero). vs. $H_a$: at least one $\rho_k \neq 0$ (at least one autocorrealtion is not zero)

The resulting p-value is less than 0.05, therefore $H_0$ is rejected, and one must conclude that at least one lag value returns a statistically significant autocorrelation.

#### Constant Variance

White's test for Heteroscedasticity is performed to confirm constant variance:

```{r}
white_lm(mlm.ts1, interactions = TRUE)
```

$H_0$: There is no Heteroscedasticity (constant variance) vs. $H_a$: There is Heteroscedasticity (no constant variance)

The resulting p-value is less than 0.05, therefore $H_0$ is rejected, and one must conclude that there exists non-constant variance within the series.

### Regression without GDP, Residual Summary

All the residual assumptions failed for this regression excluding GDP.  Therefore, assessment of the coefficients is not performed here.  Subsequent methods and analysis is required to remediate the complexities presented by this dataset.

In conjunction with resolving the residual assumptions, the variance inflation factors are computed to identify any multi-collinearities.  

```{r echo = FALSE}
vif(mlm.ts1)
```

Ten (10) is the typically accepted subjective value at which a variance inflation factor is considered high.  IndPro exceeds this limit.

A new linear model is therefore estimated without GDP and IndPro.


## Regression without GDP and IndPro

The following multiple linear regression model is estimated:

$$IIPI(`r names(mlm.ts1$coefficients)[2:length(names(mlm.ts1$coefficients))] %>% paste(sep = " ")`) = \beta_0 + \beta_1 TBillCLose + \beta_3 InfRate + \beta_5 M2 + \beta_6 UnempRate + \beta_7 Recession + \epsilon_t$$

, which results in the following estimated $\beta$ values:

```{r echo = FALSE}
mlm.ts2$coefficients
```

#### Residual Normality

The Shapiro-Wilk Test is performed to verify residual normality:

```{r}
shapiro.test(rstandard(mlm.ts2))
```

$H_0$: Series are normally distributed. vs. $H_a$: Series are not normally distributed

The resulting p-value is less than 0.05, therefore $H_0$ is rejected, and one must conclude that the series are not normally distributed.

#### Residual Autocorrelation

The Box-Pierce test is performed to identify if the residuals are autocorrelated: 

```{r}
Box.test(rstandard(mlm.ts2), lag=36)
```

$H_0$: $\rho_1=\rho_2=\rho_k=0$ (all autocorrelations are zero). vs. $H_a$: at least one $\rho_k \neq 0$ (at least one autocorrealtion is not zero)

The resulting p-value is less than 0.05, therefore $H_0$ is rejected, and one must conclude that at least one lag value returns a statistically significant autocorrelation.

The following is the autcorrelation function (ACF) chart:

```{r}
acf(rstandard(mlm.ts2))
```

This slow decay and magnitude of the autocorrelations indicate this is a non-stationary process.

#### Constant Variance

White's test for Heteroscedasticity is performed to confirm constant variance:

```{r}
white_lm(mlm.ts2, interactions = TRUE)
```

$H_0$: There is no Heteroscedasticity (constant variance) vs. $H_a$: There is Heteroscedasticity (no constant variance)

The resulting p-value is less than 0.05, therefore $H_0$ is rejected, and one must conclude that there exists non-constant variance within the series.

### Regression without GDP and IndPro, Residual Summary

All the residual assumptions failed for the regression excluding GDP and IndPro.  Subsequent methods and analysis is required to remediate the complexities presented by this dataset.

In conjunction with resolving the residual assumptions, the variance inflation factors are computed to identify any multi-collinearities.  

```{r echo = FALSE}
vif(mlm.ts2)
```

The removal of GDP and IndPro in the regression model has resolved the multicollinearity issues, as can be seen by the fact that all VIF values are much less than ten (10). 

### Regression without GDP and IndPro, Model Summary

Despite the failure of the residual assumptions a brief summary is provided of the coefficient interpretations, as if the assumptions had be met for completenes.

```{r}
summary(mlm.ts2)
```

All following statements should be seen within the context of "if the residual assumptions were met, then..."

- The expected value of IIPI if all independent variables are zero is `r mlm.ts2$coefficients[1]`.  This is not a 

- The expected change in the value of IIPI, ceteris paribus, for each unit change in inflation is `r mlm.ts2$coefficients[2]`

- The expected change in the value of IIPI, ceteris paribus, for each unit change in money supply is `r mlm.ts2$coefficients[3]`

- The expected change in the value of IIPI, ceteris paribus, for each unit change in unemployment is `r mlm.ts2$coefficients[4]`

- The expected change in the value of IIPI, ceteris paribus, if the market cycle is indicated as being in recession is `r mlm.ts2$coefficients[4]`

### Regression without GDP and IndPro, Model Fit Summary

```{r echo = FALSE}
#Plotting the confidence and prediction intervals
predint =  predict(mlm.ts2,interval="prediction")
confint =  predict(mlm.ts2,interval="confidence")
predlower = predint[,2]
predupper = predint[,3]
conflower = confint[,2]
confupper = confint[,3]

plot(df.ts.modelset.train$IIPI, col="lightgray")
lines(predint[,1],col="red")
lines(1:423,predlower,col="orange")
lines(1:423,predupper,col="orange")
lines(1:423,conflower,col="blue")
lines(1:423,confupper,col="blue")
```








Show that the AdjR2 are not usefull becasue the regression assumptions are not met.

Check if one can use a stabilizing function log(IIPI) or sqr(IIPI)

Estimate a multiple linear regression model and discuss the significance of the coefficients. 
Check multi-collinearity and check if the residual assumptions (normality, non-constant variance,
and autocorrelation) are violated. 

Intercept is the expected value of IIPI when all independent variables are zero (0)...
Coefficients, given ceteris paribus, are the expected increase / decrease of IIPI 

Plot data vs. model fit... example slide 44...

